
R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

Microsoft R Open 3.5.1
The enhanced R distribution from Microsoft
Microsoft packages Copyright (C) 2018 Microsoft Corporation

Using the Intel MKL for parallel mathematical computing (using 8 cores).

Default CRAN mirror snapshot taken on 2018-08-01.
See: https://mran.microsoft.com/.

[Previously saved workspace restored]

> library(rstanarm)
Loading required package: Rcpp
rstanarm (Version 2.18.1, packaged: )
- Do not expect the default priors to remain the same in future rstanarm versions.
Thus, R scripts should specify priors explicitly, even if they are just the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores())
- Plotting theme set to bayesplot::theme_default().
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(data.table)

Attaching package: ‘data.table’

The following objects are masked from ‘package:dplyr’:

    between, first, last

> devtools::document()
Updating mstte documentation
Loading mstte
Warning: Version of roxygen2 last used with this package is 6.1.1.  You only have version 6.1.0
Writing NAMESPACE
Writing NAMESPACE
> 
> seed = 9911
> set.seed(seed)
> 
> nscl_data = readRDS("~/rfactory/mstte-data/nscl_data.RDS")
> nscl_surv = nscl_data$nscl_surv
> tmat_mst <- mstate::trans.illdeath(names=c("diagnosis","progression","death"))
> nscl_mstte =  mstate::msprep(time=c(NA,"dp_time","os_time"),
+                              status=c(NA,"dp_status","os_status"),
+                              data = nscl_surv,
+                              trans=tmat_mst, id = "id")
Warning message:
In msprepEngine(time = time, status = status, id = id, starttime = starttime,  :
  From starting state 1, subject 4 9 17 21 22 29 39 44 51 60 74 79 86 88 89 110 111 126 128 132 138 140 144 146 159 161 177 198 203 221 229 241 268 270 273 275 295 299 307 335 357 378 395 401 408 410 412 423 426 436 457 473 474 479 486 492 503 509 513 has smallest transition time with status=0, larger transition time with status=1
> 
> nscl_mstte = left_join(nscl_mstte, nscl_surv, by = "id")
> 
> nscl_mstte$ECOGC = nscl_mstte$ECOGBL > 1
> nscl_mstte$SMKCAT = nscl_mstte$SMKCAT1N == 2
> 
> formula = lapply(1:3, function (x)
+   as.formula( Surv(time=os_time,event=os_status) ~ SMKCAT + BMIBL + SEX + ECOGC + EGFKTIFL) )
> 
> basehaz = lapply(1:3, function(x)
+   "ms")
> 
> prior_intercept = lapply(1:3, function(x)
+   rstanarm::normal() )
> 
> prior_aux = lapply(1:3, function(x)
+   rstanarm::cauchy() )
> options(mc.cores = 8L)
> fit_nscl = mstte_stan(formula = formula,
+                            data = nscl_mstte,
+                            transition_labels = c("DP", "DX", "DPDX"),
+                            prior           = lapply(1:3, function(x)
+                              rstanarm::normal() ),
+                            prior_intercept = prior_intercept,
+                            prior_aux       = prior_aux,
+                            basehaz = basehaz,
+                            seed = seed,
+                            iter = 3000, 
+                            chains = 8,
+                            adapt_delta = 0.99)

SAMPLING FOR MODEL 'mstte' NOW (CHAIN 1).
Chain 1: 
Chain 1: Gradient evaluation took 0.01 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 100 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 

SAMPLING FOR MODEL 'mstte' NOW (CHAIN 2).
Chain 2: 
Chain 2: Gradient evaluation took 0.01 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 100 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 

SAMPLING FOR MODEL 'mstte' NOW (CHAIN 3).
Chain 3: 
Chain 3: Gradient evaluation took 0 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 

SAMPLING FOR MODEL 'mstte' NOW (CHAIN 4).
Chain 4: 
Chain 4: Gradient evaluation took 0.01 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 100 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 

SAMPLING FOR MODEL 'mstte' NOW (CHAIN 5).
Chain 5: 
Chain 5: Gradient evaluation took 0 seconds
Chain 5: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 5: Adjust your expectations accordingly!
Chain 5: 
Chain 5: 
Chain 3: Iteration:    1 / 3000 [  0%]  (Warmup)

SAMPLING FOR MODEL 'mstte' NOW (CHAIN 6).
Chain 2: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 6: 
Chain 6: Gradient evaluation took 0 seconds
Chain 6: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 6: Adjust your expectations accordingly!
Chain 6: 
Chain 6: 

SAMPLING FOR MODEL 'mstte' NOW (CHAIN 7).
Chain 1: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 7: 
Chain 7: Gradient evaluation took 0 seconds
Chain 7: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 7: Adjust your expectations accordingly!
Chain 7: 
Chain 7: 

SAMPLING FOR MODEL 'mstte' NOW (CHAIN 8).
Chain 8: 
Chain 8: Gradient evaluation took 0 seconds
Chain 8: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 8: Adjust your expectations accordingly!
Chain 8: 
Chain 8: 
Chain 4: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 5: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 6: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 7: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 8: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 2: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 6: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 7: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 4: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 3: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 6: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 7: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 2: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 1: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 3: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 4: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 5: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 2: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 7: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 6: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 3: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 1: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 4: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 7: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 5: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 2: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 6: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 3: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 1: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 4: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 5: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 2: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 2: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 7: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 7: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 6: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 6: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 3: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 3: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 1: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 2: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 5: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 3: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 4: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 4: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 6: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 3: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 2: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 1: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 1: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 7: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 5: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 5: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 4: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 3: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 2: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 6: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 1: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 3: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 5: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 4: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 3: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 188.31 seconds (Warm-up)
Chain 3:                85.43 seconds (Sampling)
Chain 3:                273.74 seconds (Total)
Chain 3: 
Chain 2: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 1: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 7: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 6: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 2: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 174.61 seconds (Warm-up)
Chain 2:                126.06 seconds (Sampling)
Chain 2:                300.67 seconds (Total)
Chain 2: 
Chain 5: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 4: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 1: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 8: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 6: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 7: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 5: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 4: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 1: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 8: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 6: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 6: 
Chain 6:  Elapsed Time: 184.71 seconds (Warm-up)
Chain 6:                173.67 seconds (Sampling)
Chain 6:                358.38 seconds (Total)
Chain 6: 
Chain 1: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 228.07 seconds (Warm-up)
Chain 1:                140.35 seconds (Sampling)
Chain 1:                368.42 seconds (Total)
Chain 1: 
Chain 5: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 4: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 207.04 seconds (Warm-up)
Chain 4:                163.67 seconds (Sampling)
Chain 4:                370.71 seconds (Total)
Chain 4: 
Chain 8: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 7: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 5: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 5: 
Chain 5:  Elapsed Time: 236.2 seconds (Warm-up)
Chain 5:                167.43 seconds (Sampling)
Chain 5:                403.63 seconds (Total)
Chain 5: 
Chain 8: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 7: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 7: 
Chain 7:  Elapsed Time: 183 seconds (Warm-up)
Chain 7:                252.41 seconds (Sampling)
Chain 7:                435.41 seconds (Total)
Chain 7: 
Chain 8: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 8: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 8: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 8: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 8: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 8: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 8: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 8: 
Chain 8:  Elapsed Time: 448.65 seconds (Warm-up)
Chain 8:                282.23 seconds (Sampling)
Chain 8:                730.88 seconds (Total)
Chain 8: 
> 
> saveRDS(nlist(fit_nscl, nscl_mstte), "~/rfactory/mstte-data/baseline_nscl_fit.RDS")
> 
> proc.time()
    user   system  elapsed 
3255.043    2.058  742.665 
