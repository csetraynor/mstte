
R version 3.5.1 (2018-07-02) -- "Feather Spray"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

Microsoft R Open 3.5.1
The enhanced R distribution from Microsoft
Microsoft packages Copyright (C) 2018 Microsoft Corporation

Using the Intel MKL for parallel mathematical computing (using 8 cores).

Default CRAN mirror snapshot taken on 2018-08-01.
See: https://mran.microsoft.com/.

[Previously saved workspace restored]

> library(rstanarm)
Loading required package: Rcpp
rstanarm (Version 2.18.1, packaged: )
- Do not expect the default priors to remain the same in future rstanarm versions.
Thus, R scripts should specify priors explicitly, even if they are just the defaults.
- For execution on a local, multicore CPU with excess RAM we recommend calling
options(mc.cores = parallel::detectCores())
- Plotting theme set to bayesplot::theme_default().
> library(dplyr)

Attaching package: ‘dplyr’

The following objects are masked from ‘package:stats’:

    filter, lag

The following objects are masked from ‘package:base’:

    intersect, setdiff, setequal, union

> library(data.table)

Attaching package: ‘data.table’

The following objects are masked from ‘package:dplyr’:

    between, first, last

> devtools::document()
Updating mstte documentation
Loading mstte
Warning: Version of roxygen2 last used with this package is 6.1.1.  You only have version 6.1.0
Writing NAMESPACE
Writing NAMESPACE
> set.seed(9911)
> 
> nscl_data = readRDS("~/rfactory/mstte-data/nscl_data.RDS")
> nscl_ldh = nscl_data$nscl_ldh
> 
> tmat_mst <- mstate::trans.illdeath(names=c("diagnosis","progression","death"))
> nscl_mstte =  suppressWarnings( mstate::msprep(time=c(NA,"dp_time","os_time"),
+                                                status=c(NA,"dp_status","os_status"),
+                                                data = nscl_data$nscl_surv,
+                                                trans=tmat_mst, id = "id")
+ )
> nscl_mstte = left_join(nscl_mstte, nscl_data$nscl_surv, by = "id")
> 
> rm(nscl_data)
> 
> length(unique(nscl_ldh$id))
[1] 530
> length(unique(nscl_mstte$id))
[1] 530
> all(nscl_mstte$id %in% nscl_ldh$id)
[1] TRUE
> 
> 
> dupe = nscl_ldh[,c('USUBJID','time')] # select columns to check duplicates
> une = unique( nscl_ldh[duplicated(dupe) | duplicated(dupe, fromLast=TRUE),] )
> 
> nscl_ldh = nscl_ldh [!(duplicated(dupe) | duplicated(dupe, fromLast=TRUE) ),] 
> nscl_ldh = rbind(une, nscl_ldh)
> nscl_ldh = nscl_ldh[order(nscl_ldh$id, nscl_ldh$time), ]
> 
> 
> options(mc.cores = 8L)
> stanfit = msjm_stan(formulaLong = ldh ~  time + ECOGBL + BMIBL + SEX + EGFKTIFL + (1 | id),
+                   dataLong = nscl_ldh,
+                   formulaMs = lapply(1:3, function (x){
+                     Surv(time=time,event=status) ~ ECOGBL + BMIBL + SEX + EGFKTIFL }),
+                   dataMs = nscl_mstte,
+                   time_var = "time",
+                   transition_labels = c("01", "02", "12"),
+                   time_start = "Tstart",
+                   id_var = "id",
+                   init = "prefit",
+                   family = gaussian,
+                   assoc = "etavalue",
+                   lag_assoc = 0,
+                   epsilon = 1E-5,
+                   prior_PD = FALSE,
+                   priorLong = rstanarm::normal(),
+                   priorLong_intercept = rstanarm::normal(),
+                   priorLong_aux = rstanarm::cauchy(0, 5),
+                   prior_covariance = rstanarm::lkj(),
+                   priorMs_intercept = lapply(1:3, function(x)
+                     rstanarm::normal() ),
+                   priorMs_aux = lapply(1:3, function(x)
+                     rstanarm::cauchy() ),
+                   priorMs = lapply(1:3, function(x)
+                     rstanarm::normal() ),
+                   priorMs_assoc = lapply(1:3, function(x)
+                     rstanarm::normal() ),
+                   basehaz = lapply(1:3, function(x)
+                     "bs"),
+                   seed = 57489,
+                   iter = 3000, 
+                   chains = 8,
+                   adapt_delta = 0.99)
Fitting a univariate joint multi-state model with 3 states.

Please note the warmup may be much slower than later iterations!

SAMPLING FOR MODEL 'msjm' NOW (CHAIN 2).

SAMPLING FOR MODEL 'msjm' NOW (CHAIN 3).

SAMPLING FOR MODEL 'msjm' NOW (CHAIN 4).

SAMPLING FOR MODEL 'msjm' NOW (CHAIN 5).

SAMPLING FOR MODEL 'msjm' NOW (CHAIN 6).

SAMPLING FOR MODEL 'msjm' NOW (CHAIN 7).
Chain 2: 
Chain 2: Gradient evaluation took 0.01 seconds
Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 100 seconds.
Chain 2: Adjust your expectations accordingly!
Chain 2: 
Chain 2: 
Chain 4: 
Chain 4: Gradient evaluation took 0.01 seconds
Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 100 seconds.
Chain 4: Adjust your expectations accordingly!
Chain 4: 
Chain 4: 
Chain 3: 
Chain 3: Gradient evaluation took 0.01 seconds
Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 100 seconds.
Chain 3: Adjust your expectations accordingly!
Chain 3: 
Chain 3: 
Chain 5: 
Chain 5: Gradient evaluation took 0 seconds
Chain 5: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
Chain 5: Adjust your expectations accordingly!
Chain 5: 
Chain 5: 
Chain 7: 
Chain 7: Gradient evaluation took 0.01 seconds
Chain 7: 1000 transitions using 10 leapfrog steps per transition would take 100 seconds.
Chain 7: Adjust your expectations accordingly!
Chain 7: 
Chain 7: 

SAMPLING FOR MODEL 'msjm' NOW (CHAIN 1).
Chain 6: 
Chain 6: Gradient evaluation took 0.02 seconds
Chain 6: 1000 transitions using 10 leapfrog steps per transition would take 200 seconds.
Chain 6: Adjust your expectations accordingly!
Chain 6: 
Chain 6: 
Chain 1: 
Chain 1: Gradient evaluation took 0.02 seconds
Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 200 seconds.
Chain 1: Adjust your expectations accordingly!
Chain 1: 
Chain 1: 

SAMPLING FOR MODEL 'msjm' NOW (CHAIN 8).
Chain 8: 
Chain 8: Gradient evaluation took 0.02 seconds
Chain 8: 1000 transitions using 10 leapfrog steps per transition would take 200 seconds.
Chain 8: Adjust your expectations accordingly!
Chain 8: 
Chain 8: 
Chain 2: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 4: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 6: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 3: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 7: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 1: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 5: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 8: Iteration:    1 / 3000 [  0%]  (Warmup)
Chain 6: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 1: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 7: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 5: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 4: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 3: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 6: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 2: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 4: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 8: Iteration:  300 / 3000 [ 10%]  (Warmup)
Chain 1: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 5: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 6: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 7: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 3: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 4: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 2: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 1: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 5: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 8: Iteration:  600 / 3000 [ 20%]  (Warmup)
Chain 6: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 3: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 2: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 4: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 1: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 5: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 6: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 6: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 7: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 3: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 2: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 1: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 1: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 5: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 5: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 4: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 4: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 8: Iteration:  900 / 3000 [ 30%]  (Warmup)
Chain 6: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 1: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 3: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 3: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 5: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 2: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 2: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 4: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 6: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 1: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 7: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 3: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 5: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 2: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 4: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 8: Iteration: 1200 / 3000 [ 40%]  (Warmup)
Chain 1: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 6: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 3: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 5: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 2: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 1: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 4: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 6: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 7: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 7: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 3: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 1: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 1: 
Chain 1:  Elapsed Time: 1740.94 seconds (Warm-up)
Chain 1:                1035.44 seconds (Sampling)
Chain 1:                2776.38 seconds (Total)
Chain 1: 
Chain 5: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 2: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 4: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 8: Iteration: 1500 / 3000 [ 50%]  (Warmup)
Chain 8: Iteration: 1501 / 3000 [ 50%]  (Sampling)
Chain 6: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 6: 
Chain 6:  Elapsed Time: 1630.78 seconds (Warm-up)
Chain 6:                1240.3 seconds (Sampling)
Chain 6:                2871.08 seconds (Total)
Chain 6: 
Chain 7: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 3: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 5: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 5: 
Chain 5:  Elapsed Time: 1780.45 seconds (Warm-up)
Chain 5:                1233.69 seconds (Sampling)
Chain 5:                3014.14 seconds (Total)
Chain 5: 
Chain 2: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 8: Iteration: 1800 / 3000 [ 60%]  (Sampling)
Chain 4: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 4: 
Chain 4:  Elapsed Time: 1798.52 seconds (Warm-up)
Chain 4:                1263.23 seconds (Sampling)
Chain 4:                3061.75 seconds (Total)
Chain 4: 
Chain 7: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 3: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 3: 
Chain 3:  Elapsed Time: 2002 seconds (Warm-up)
Chain 3:                1189.13 seconds (Sampling)
Chain 3:                3191.13 seconds (Total)
Chain 3: 
Chain 2: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 2: 
Chain 2:  Elapsed Time: 2033.86 seconds (Warm-up)
Chain 2:                1192.06 seconds (Sampling)
Chain 2:                3225.92 seconds (Total)
Chain 2: 
Chain 8: Iteration: 2100 / 3000 [ 70%]  (Sampling)
Chain 7: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 8: Iteration: 2400 / 3000 [ 80%]  (Sampling)
Chain 7: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 8: Iteration: 2700 / 3000 [ 90%]  (Sampling)
Chain 7: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 7: 
Chain 7:  Elapsed Time: 2675.8 seconds (Warm-up)
Chain 7:                1021.17 seconds (Sampling)
Chain 7:                3696.97 seconds (Total)
Chain 7: 
Chain 8: Iteration: 3000 / 3000 [100%]  (Sampling)
Chain 8: 
Chain 8:  Elapsed Time: 2840.11 seconds (Warm-up)
Chain 8:                968.29 seconds (Sampling)
Chain 8:                3808.4 seconds (Total)
Chain 8: 
> 
> saveRDS(stanfit, "~/rfactory/mstte-data/nscl_bs_fit.RDS")
> 
> #  After fitting
> # 
> # stanfit = readRDS("~/rfactory/mstte-data/nscl_bs_fit.RDS")
> # sumfit = rstan::summary(stanfit)
> # sumfit[!grepl("b\\[Long1|posterior", rownames(sumfit)), ]
> 
> 
> 
> 
> 
> proc.time()
     user    system   elapsed 
25575.494   106.580  3848.376 
